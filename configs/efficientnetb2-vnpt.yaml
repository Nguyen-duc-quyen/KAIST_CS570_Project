# General training configuration
exp_name: "efficientnetb2-vnpt"
output_dir: "./exp_results"
num_epochs: 100
warmup_epochs: 0
finish_epochs: 0
decay_epochs: [60, 80, 90]
log_rate: 10
save_rate: 10
interval: 0
device: "single" # Support "cpu", "single", "ddp", and "auto"
gpus: [0] # List of gpu indices, if in "single" mode only run on the first GPU
use_tensorboard: False
use_wandb: True
precision: "fp32" # Support "fp32", "fp16" and "mixed"
base_lr: 5e-4 # Base learning rate
batchsize: 64

# Model configuration
model:
  backbone:
    name: "efficientnet_b2"
    input_size: 224
  classifier:
    name: "linear"
    bn: False
    pool: "avg"
    scale: 1
    num_classes: 1
    dropout: 0.0
  pretrained: False
  weights: None
  multi_scale: False

# Training dataset configuration
train_data:
  type: "VNPT-Thyroid"
  shuffle: True
  image_dir: "/home/jovyan/quyen-data/Datasets/vnpt_thyroid_v1.0.0/train/images"
  label_dir: "/home/jovyan/quyen-data/Datasets/vnpt_thyroid_v1.0.0/train/labels_orig"
  batchsize: ${batchsize}
  num_workers: 16
  transforms:
    # - _target_: datasets.transforms.CropBboxWithArea
    #   pixel: 0
    - _target_: albumentations.augmentations.BBoxSafeRandomCrop
    - _target_: albumentations.Resize
      height: ${model.backbone.input_size}
      width: ${model.backbone.input_size}
    - _target_: albumentations.augmentations.RandomBrightnessContrast
    - _target_: albumentations.augmentations.SafeRotate
      limit: 5
    - _target_: albumentations.augmentations.HorizontalFlip
    - _target_: albumentations.Normalize
      #mean: [0.5, 0.5, 0.5]    # the default mean values
      #std: [0.25, 0.25, 0.25]  # the default std values
      mean: [0.4, 0.4, 0.4]     # mean extracted from the VNPT-Thyroid training set
      std: [0.18, 0.18, 0.18]   # std extracted from the VNPT-Thyroid training set
      max_pixel_value: 255.0
    - _target_: albumentations.pytorch.ToTensorV2

# Test dataset configuration
test_data:
  type: "VNPT-Thyroid"
  crop: False
  shuffle: False
  image_dir: "/home/jovyan/quyen-data/Datasets/vnpt_thyroid_v1.0.0/test/images"
  label_dir: "/home/jovyan/quyen-data/Datasets/vnpt_thyroid_v1.0.0/test/labels_orig"
  batchsize: ${batchsize}
  num_workers: 16
  transforms:
    # - _target_: datasets.transforms.CropBboxWithArea
    #   pixel: 0
    - _target_: albumentations.Resize
      height: ${model.backbone.input_size}
      width: ${model.backbone.input_size}
    - _target_: albumentations.Normalize
      #mean: [0.5, 0.5, 0.5]    # the default mean values
      #std: [0.25, 0.25, 0.25]  # the default std values
      mean: [0.4, 0.4, 0.4]     # mean extracted from the VNPT-Thyroid training set
      std: [0.18, 0.18, 0.18]   # std extracted from the VNPT-Thyroid training set
      max_pixel_value: 255.0
    - _target_: albumentations.pytorch.ToTensorV2

# Optimizer configuration
optimizer:
  _target_: torch.optim.AdamW
  lr: ${base_lr}
  weight_decay: 5e-5

# Learning rate scheduler configuration
# lr_scheduler:
#   _target_: lr_schedulers.custom_lr_schedulers.MultiStepLRWithWarmUp
#   num_warmup_steps: 10 # Placeholder, can be updated dynamically
#   base_lr: ${base_lr}
#   decay_steps: [60, 80, 90]
#   gamma: 0.1
#   last_epoch: -1
lr_scheduler: "None"

# Loss function configuration
loss:
  _target_: torch.nn.BCEWithLogitsLoss
  reduction: "mean"

# Metrics configuration
metrics:
  - _target_: torcheval.metrics.BinaryAccuracy
  - _target_: torcheval.metrics.BinaryPrecision
  - _target_: torcheval.metrics.BinaryRecall
  - _target_: torcheval.metrics.BinaryF1Score
  - _target_: metrics.custom_metrics.BinarySensitivity
  - _target_: metrics.custom_metrics.BinarySpecificity

# Setting the F1-score as the main metric
# The final metric can be the combination of different metrics
metrics_weights: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]